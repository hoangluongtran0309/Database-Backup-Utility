# 🗄️ Database Backup Utility 

## 📖 Overview
Database Backup Utility Database Backup Utility Project - https://roadmap.sh/projects/database-backup-utility

The **Database Backup Utility** is a command-line application built with **Spring Shell** that provides an easy way to back up, compress, restore, and schedule database backups.  
It uses **Quartz Scheduler** for job scheduling and supports **file compression** and **cloud storage integration** (AWS, Azure, GCP).

> 🎯 The goal is to simplify database maintenance through an extensible, scriptable, and interactive CLI tool.

---

## ⚙️ Key Features

- 🧰 **Interactive CLI with Spring Shell** — Run commands directly to connect, back up, restore, and manage backups.  
- ⏰ **Quartz Scheduler Integration** — Automate backups using cron expressions.  
- 🗜️ **File Compression Support** — Supports `ZIP`, `GZIP`, and `TAR.GZ` formats.  
- ☁️ **Cloud Storage Integration** — Upload/download backups from AWS S3, Azure Blob, and GCP Cloud Storage.  
- 🧩 **Extensible Architecture** — Easily extend support for new databases or storage providers.  

---

## 🧠 Architecture Overview

![Architecture Diagram](/flowchart_database_backup_utility.png?raw=true "Database Backup Utility")

---

## 💻 Technologies Used

| Component | Purpose |
|------------|----------|
| **Spring Shell** | Provides the interactive command-line interface |
| **Quartz Scheduler** | Handles job scheduling and cron-based automation |
| **Java NIO / ProcessBuilder** | Executes database dump commands and file I/O |
| **SLF4J + Logback** | Logging |
| **Lombok** | Reduces boilerplate code |
| **Jakarta Validation** | Input validation for CLI options |
| **AWS / Azure / GCP SDKs** | Cloud storage integration |

---

## 📂 Project Structure

```bash
database-backup-utility/
 ├── .env                                 # 🌱 Environment variables file (Spring Boot auto-loaded) 
 ├── pom.xml                              # Maven build configuration
 ├── README.md                            # Project documentation
 ├── .gitignore                           # Git ignore rules
 │
 ├── src/
 │   ├── main/java/dbu/                   # Main application source
 │   │   ├── commands/                    # 🧭 CLI Commands
 │   │   ├── services/                    # ⚙️ Business logic (backup, restore, scheduler, storage)
 │   │   ├── models/                      # 🧱 DTOs and configuration classes
 │   │   ├── enums/                       # 🧩 Enums (DatabaseType, CompressType, StorageType)
 │   │   ├── exceptions/                  # ⚠️ Custom exceptions
 │   │   └── utils/                       # 🔧 Utility classes
 │   │
 │   ├── resources/
 │   │   ├── application.yml              # Spring Boot configuration (imports .env)
 │   │   ├── banner.txt                   # ASCII startup banner
 │   │   └── quartz_tables.sql            # SQL schema for Quartz (if using JDBC store)
 │   │
 │   └── test/                            # 🧪 Unit & Integration Tests
 │       ├── backup/
 │       ├── connect/
 │       └── restore/
 │
 └── target/                              # ⚙️ Build output (generated by Maven)
```

---

## 🚀 Getting Started

### 1️⃣ Prerequisites

- Java **17** or higher  
- **Maven** or **Gradle**  
- Installed database tools (`pg_dump`, `mysqldump`, `mongodump`)  
- Network access to your database and cloud provider  

---

### 2️⃣ Installation

#### Clone and build the project:

```bash
git clone https://github.com/yourusername/database-backup-utility.git
cd database-backup-utility
mvn clean package
```
#### Config the project:

You can select either of the two options:

Create your own `.env` file (Option 1):

Run this command in the root directory of the `database-backup-utility` project to create an empty `.env` file.

```bash
touch .env 
```

Then open the .env file with your preferred text editor (e.g., vim, nano, code, etc.) and replace the placeholder values with your actual configuration.

```properties
#This is example .env file
#Note: Please place the .env file in the root directory of the database-backup-utility project. 
DB_HOST=your_db_host
DB_PORT=your_db_port
DB_NAME=your_db_name
DB_USER=your_db_user
DB_PASS=your_db_password

AWS_ACCESS_KEY=your_aws_access_key
AWS_SECRET_KEY=your_aws_secret_key
AWS_BUCKET_NAME=your-aws-bucket-name
AWS_REGION=your-aws-bucket-region

AZURE_CONNECTION_STRING=your_azure_connection_string
AZURE_CONTAINER_NAME=your-azure-container-name

GCP_CREDENTIALS_PATH=your-credentials-path #e.g. /home/user/gcp-credentials.json
GCP_BUCKET_NAME=your-gcp-bucket-name
```

Export environment variable (Option 2):
```bash
export DB_HOST=your_db_host
export DB_PORT=your_db_port
export DB_NAME=your_db_name
export DB_USER=your_db_user
export DB_PASS=your_db_password

export AWS_ACCESS_KEY=your_aws_access_key
export AWS_SECRET_KEY=your_aws_secret_key
export AWS_BUCKET_NAME=your-aws-bucket-name
export AWS_REGION=your-aws-bucket-region

export AZURE_CONNECTION_STRING=your_azure_connection_string
export AZURE_CONTAINER_NAME=your-azure-container-name

export GCP_CREDENTIALS_PATH=your-credentials-path #e.g. /home/user/gcp-credentials.json
export GCP_BUCKET_NAME=your-gcp-bucket-name
```

#### Run the CLI:

```bash
java -jar target/database-backup-utility.jar
```

---

## 💬 Spring Shell CLI

When the app starts, you’ll see a prompt like this:

```
shell:>_
```

Type `help` to view all available commands.

---

## 🧭 Usage Guide

### ⚙️ 1. Connect to a Database

```bash
connect --database-type <TYPE> --host <HOST> --port <PORT> --database <DB_NAME> --user <USER> --password <PASSWORD>
```

**Example:**
```bash
shell:> connect --database-type MYSQL --host localhost --port 3306 --database sales --user root --password pass123
```
✅ Output:
```
Successfully connected to database: sales [MYSQL] 
```

---

### 💾 2. Backup a Database

```bash
backup --database-type <TYPE> --host <HOST> --port <PORT> --database <DB_NAME> --user <USER> --password <PASSWORD> --output <OUTPUT_PATH> --compress <TYPE> --cron <CRON_EXPRESSION>
```

**Example 1: Immediate Backup**
```bash
shell:> backup --database-type POSTGRESQL --database mydb --user admin --password pass123 --output ./backups --compress GZIP
```
✅ Output:
```
Database backup completed successfully: ./backups/backup_mydb_2025-10-23.gzip
```

**Example 2: Scheduled Backup**
```bash
shell:> backup --database-type MYSQL --database sales --user root --password 12345 --output ./backups --compress ZIP --cron "0 0 3 * * ?"
```
✅ Output:
```
Backup schedule created successfully. The database will be backed up according to the cron schedule: 0 0 3 * * ?
```

---

### 🔁 3. Restore a Database

```bash
restore --database-type <TYPE> --database <DB_NAME> --user <USER> --password <PASSWORD> --input-path <BACKUP_FILE_PATH>
```

**Example:**
```bash
shell:> restore --database-type POSTGRESQL --database mydb --user admin --password pass123 --input-path ./backups/backup_mydb_2025-10-22.zip
```
✅ Output:
```
Database restore successful.
```

---

### ☁️ 4. Cloud Storage Commands

**Upload a Backup File**
```bash
upload --storage-type <TYPE> --key <REMOTE_PATH> --file-path <LOCAL_FILE>
```

**Example:**
```bash
shell:> upload --storage-type AWS --key backups/mydb_2025-10-23.gzip --file-path ./backups/backup_mydb_2025-10-23.gzip
```
✅ Output:
```
Upload successful! URL: https://s3.amazonaws.com/mybucket/backups/mydb_2025-10-23.gzip
```

**Download a File**
```bash
download --storage-type <TYPE> --key <REMOTE_PATH> --destination <LOCAL_DIR>
```

**Example:**
```bash
shell:> download --storage-type GCP --key backups/sales_2025-10-20.zip --destination ./downloads
```
✅ Output:
```
Download successful! Saved to: ./downloads/sales_2025-10-20.zip
```

**Delete a File**
```bash
delete --storage-type <TYPE> --key <REMOTE_PATH>
```

**Example:**
```bash
shell:> delete --storage-type GCP --key backups/sales_2025-10-20.zip 
```
✅ Output:
```
File deleted successfully.
```

**List All Files**
```bash
list --storage-type <TYPE>
```

**Example:**
```bash
shell:> list --storage-type GCP 
```
✅ Output:
```
Files in storage:
backups/sales_2025-10-20.zip
backups/sales_2025-10-22.zip
backups/sales_2025-10-24.zip
```

**Check if a File Exists**
```bash
check --storage-type <TYPE> --key <REMOTE_PATH>
```

**Example:**
```bash
shell:> check --storage-type AWS --key backups/mydb_2025-10-23.gzip
```
✅ Output:
```
File exists: true
```

---

## 🧩 Example Workflow

```bash
# 1. Connect
shell:> connect --database-type POSTGRESQL --database mydb --user admin --password 1234

# 2. Backup & Compress
shell:> backup --database-type POSTGRESQL --database mydb --user admin --password 1234 --output ./backups --compress ZIP

# 3. Upload to S3
shell:> upload --storage-type AWS --key backups/mydb_latest.zip --file-path ./backups/backup_mydb_latest.zip

# 4. Schedule daily backups at 2 AM
shell:> backup --database-type POSTGRESQL --database mydb --user admin --password 1234 --output ./backups --cron "0 0 2 * * ?"
```

---

## 🗜️ Compression Options

| Type | Extension | Description |
|-------|------------|-------------|
| **NONE** | (no compression) | Raw dump file |
| **ZIP** | `.zip` | Standard compression |
| **GZIP** | `.gzip` | Fast single-file compression |
| **TAR.GZ** | `.tar.gz` | Common on Linux/Unix |

---

## 🧱 Scheduling with Quartz

Automate periodic backups using cron expressions.  
Example:
```bash
shell:> backup --database-type POSTGRESQL --database mydb --user admin --password pass123 --output ./backups --cron "0 0 3 * * ?"
```
✅ Backup schedule created successfully. The database will be backed up according to the cron schedule: **0 0 3 * * ?**.

---
